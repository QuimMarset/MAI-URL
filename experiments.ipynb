{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsupervised Learning : Cluster Assignment\n",
    "\n",
    "#### Paper: Alternatives to the k-means algorithm that find better clusterings\n",
    "\n",
    "#### Author: Joaquim Marset Alsina"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.birch_data import generate_birch_data\n",
    "from datasets.pelleg_moore_data import generate_pelleg_moore_data\n",
    "from datasets.image_data import *\n",
    "from datasets.adult_data import AdultData\n",
    "\n",
    "from experiments import experiment_1, experiment_2, experiment_3, experiment_4\n",
    "from utils.cluster_initialization import *\n",
    "\n",
    "\n",
    "from utils.plot_utils import *\n",
    "from utils.string_utils import *\n",
    "from utils.metrics import evaluate_resulting_clusters\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create required folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = './'\n",
    "\n",
    "datasets_path = os.path.join(root_path, 'datasets')\n",
    "images_path = os.path.join(datasets_path, 'images')\n",
    "\n",
    "results_path = os.path.join(root_path, 'results')\n",
    "experiment_1_results_path = os.path.join(results_path, 'experiment_1')\n",
    "experiment_2_results_path = os.path.join(results_path, 'experiment_2')\n",
    "experiment_3_results_path = os.path.join(results_path, 'experiment_3')\n",
    "experiment_4_results_path = os.path.join(results_path, 'experiment_4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(results_path, exist_ok=True)\n",
    "os.makedirs(experiment_1_results_path, exist_ok=True)\n",
    "os.makedirs(experiment_2_results_path, exist_ok=True)\n",
    "os.makedirs(experiment_3_results_path, exist_ok=True)\n",
    "os.makedirs(experiment_4_results_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1: Convergence properties of the 5 described algorithms on the BIRCH synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This first experiment belongs to the paper. The authors wanted to test the convergence of the 5 described algorithms using a synthetic data they extracted \n",
    "# from the BIRCH paper\n",
    "\n",
    "grid_size = 10\n",
    "num_clusters = grid_size * grid_size\n",
    "points_per_cluster = 100\n",
    "center_distance = 4 * np.sqrt(2)\n",
    "\n",
    "birch_data, true_clustering, true_centers = generate_birch_data(grid_size, center_distance, points_per_cluster)\n",
    "\n",
    "cluster_radius = np.linalg.norm(true_centers[1] - true_centers[0]) / 4\n",
    "\n",
    "plot_generated_synthetic_data(birch_data, true_centers, true_clustering, BIRCH, experiment_1_results_path, points_per_cluster)\n",
    "\n",
    "# They considered to perform only 100 iterations and 1 repetition of the execution, and compute the number of true clusterings each algorithm was able to find\n",
    "# as well as compute the quality of the predicted clustering. This quality was computed as the squared root of the K-Means objective as a way to unify the comparison\n",
    "# even though each algorithm minimizes its own objective function\n",
    "\n",
    "# They repeated the experiment 2 times with different cluster initializations: Forgy and Random partition\n",
    "\n",
    "repetitions = 1\n",
    "iterations = 500\n",
    "\n",
    "# Before running the algorithms, we are going to plot the initial centers to see how each initialization method works\n",
    "\n",
    "initial_centers_forgy = initialize_centers_forgy(num_clusters, birch_data)\n",
    "initial_centers_rand_part = initialzie_centers_random_partition(num_clusters, birch_data)\n",
    "\n",
    "plot_initial_cluster_centers(birch_data, initial_centers_forgy, BIRCH, FORGY, experiment_1_results_path)\n",
    "\n",
    "plot_initial_cluster_centers(birch_data, initial_centers_rand_part, BIRCH, RANDPART, experiment_1_results_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forgy initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_function = experiment_1.run_kmeans\n",
    "fuzzy_cmeans_function = experiment_1.run_fuzzy_c_means\n",
    "kharmonic_function = experiment_1.run_kharmonic\n",
    "hybrid_1_function = experiment_1.run_hybrid_1\n",
    "hybrid_2_function = experiment_1.run_hybrid_2\n",
    "gem_function = experiment_1.run_gaussian_em\n",
    "\n",
    "# We define some parameters as a dictionary as we have tried to create a unified framework to run the experiment\n",
    "kmeans_params = {\n",
    "    'iterations' : iterations,\n",
    "    'repetitions' : repetitions\n",
    "}\n",
    "\n",
    "fuzzy_cmeans_params = {\n",
    "    'fuzzy_degree' : 1.3,\n",
    "    'convergence_threshold' : 0.0001,\n",
    "    'iterations' : iterations,\n",
    "    'repetitions' : repetitions\n",
    "}\n",
    "\n",
    "kharmonic_params = {\n",
    "    'p' : 3.5,\n",
    "    'convergence_threshold' : 0.0001,\n",
    "    'iterations' : iterations,\n",
    "    'repetitions' : repetitions\n",
    "}\n",
    "\n",
    "gem_params = {\n",
    "    'iterations': iterations, \n",
    "    'repetitions': repetitions,\n",
    "    'cov_init_value': 0.2, \n",
    "    'convergence_threshold': 0.0001\n",
    "}\n",
    "\n",
    "experiment_1.run_algorithm_with_birch_data(birch_data, num_clusters, initial_centers_forgy, FORGY, KMEANS, \n",
    "    experiment_1_results_path, kmeans_function, kmeans_params)\n",
    "\n",
    "experiment_1.run_algorithm_with_birch_data(birch_data, num_clusters, initial_centers_forgy, FORGY, FCMEANS, \n",
    "    experiment_1_results_path, fuzzy_cmeans_function, fuzzy_cmeans_params)\n",
    "\n",
    "experiment_1.run_algorithm_with_birch_data(birch_data, num_clusters, initial_centers_forgy, FORGY, KHARMONIC, \n",
    "    experiment_1_results_path, kharmonic_function, kharmonic_params)\n",
    "\n",
    "experiment_1.run_algorithm_with_birch_data(birch_data, num_clusters, initial_centers_forgy, FORGY, HYBRID1, \n",
    "    experiment_1_results_path, hybrid_1_function, kharmonic_params)\n",
    "\n",
    "experiment_1.run_algorithm_with_birch_data(birch_data, num_clusters, initial_centers_forgy, FORGY, HYBRID2, \n",
    "    experiment_1_results_path, hybrid_2_function, kharmonic_params)\n",
    "\n",
    "experiment_1.run_algorithm_with_birch_data(birch_data, num_clusters, initial_centers_forgy, \n",
    "    FORGY, GEM, experiment_1_results_path, gem_function, gem_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random partition initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We repeat the process with the other cluster initialization\n",
    "\n",
    "experiment_1.run_algorithm_with_birch_data(birch_data, num_clusters, initial_centers_rand_part, \n",
    "    RANDPART, KMEANS, experiment_1_results_path, kmeans_function, kmeans_params)\n",
    "\n",
    "experiment_1.run_algorithm_with_birch_data(birch_data, num_clusters, initial_centers_rand_part, \n",
    "    RANDPART, FCMEANS, experiment_1_results_path, fuzzy_cmeans_function, fuzzy_cmeans_params)\n",
    "\n",
    "experiment_1.run_algorithm_with_birch_data(birch_data, num_clusters, initial_centers_rand_part, \n",
    "    RANDPART, KHARMONIC, experiment_1_results_path, kharmonic_function, kharmonic_params)\n",
    "\n",
    "experiment_1.run_algorithm_with_birch_data(birch_data, num_clusters, initial_centers_rand_part, \n",
    "    RANDPART, HYBRID1, experiment_1_results_path, hybrid_1_function, kharmonic_params)\n",
    "\n",
    "experiment_1.run_algorithm_with_birch_data(birch_data, num_clusters, initial_centers_rand_part, \n",
    "    RANDPART, HYBRID2, experiment_1_results_path, hybrid_2_function, kharmonic_params)\n",
    "\n",
    "experiment_1.run_algorithm_with_birch_data(birch_data, num_clusters, initial_centers_rand_part, \n",
    "    RANDPART, GEM, experiment_1_results_path, gem_function, gem_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2: Paper's second experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this experiment the authors wanted to see the average-case behaviour of the described algorithms. \n",
    "# This is why they created multiple synthetic algorithms based on a particular paper (which they called Pelleg and Moore data honouring the authors)\n",
    "# They wanted to test different number of dimensions for the data, creating multiple datasets for each dimension. In particular, \n",
    "# they created data with 2, 4, and 6 dimensions, creating 100 datasets for each. Each dataset contains 50 clusters and a total of 2500 points\n",
    "# As before, they repeated the experiment with both initializations\n",
    "\n",
    "dimensions_list = [2, 4, 6]\n",
    "num_datasets = 100\n",
    "num_clusters = 50\n",
    "points_per_cluster = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The clusters centers are generated random by sampling in the unit hypercube, and the points are generated according to a Gaussian\n",
    "# centered in the true center with a standard deviation of num_dimensions*0.012\n",
    "\n",
    "std_factor = 0.012\n",
    "\n",
    "# Each algorithm runs for 100 iterations, all sharing the same centers\n",
    "iterations = 100\n",
    "\n",
    "# To compute the quality metric we need to run a k-means with the real centers and let it converge. We are assuming they are referring \n",
    "# to the real centers because the paper says \"running KM to convergence starting with the centers that generated the data sets\"\n",
    "# Therefore, it will probably last a few iterations, but the objective function at convergence will not change\n",
    "optimal_kmeans_iterations = 500\n",
    "\n",
    "# We are assuming as the previous experiment only one repetition of each algorithm with each initialization method\n",
    "repetitions = 1\n",
    "\n",
    "# We define the other algorithm parameters as the authors did\n",
    "fuzzy_degree = 1.3\n",
    "p = 3.5\n",
    "convergence_threshold = 0.001\n",
    "cov_init_value = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot an example of dataset with 2 dimensions\n",
    "pelleg_data, true_clustering, true_centers = generate_pelleg_moore_data(2, num_clusters, points_per_cluster, std_factor)\n",
    "plot_generated_synthetic_data(pelleg_data, true_centers, true_clustering, PELLEG, experiment_2_results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_function = experiment_2.run_kmeans\n",
    "fuzzy_function = experiment_2.run_fuzzy_c_means\n",
    "kharmonic_function = experiment_2.run_kharmonic\n",
    "hybrid_1_function = experiment_2.run_hybrid_1\n",
    "hybrid_2_function = experiment_2.run_hybrid_2\n",
    "gaussian_em_function = experiment_2.run_gaussian_em\n",
    "\n",
    "kmeans_params = {'iterations': iterations, 'repetitions': repetitions}\n",
    "fuzzy_params = {'iterations': iterations, 'repetitions': repetitions, 'fuzzy_degree': fuzzy_degree, 'convergence_threshold': convergence_threshold}\n",
    "kharmonic_params = {'iterations': iterations, 'repetitions': repetitions, 'p': p, 'convergence_threshold': convergence_threshold}\n",
    "gaussian_em_params = {'iterations': iterations, 'repetitions': repetitions, 'cov_init_value': cov_init_value, 'convergence_threshold': convergence_threshold}\n",
    "\n",
    "functions = [kmeans_function, fuzzy_function, kharmonic_function, hybrid_1_function, hybrid_2_function]\n",
    "params = [kmeans_params, fuzzy_params, kharmonic_params, kharmonic_params, kharmonic_params, gaussian_em_params]\n",
    "names = [KMEANS, FCMEANS, KHARMONIC, HYBRID1, HYBRID2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment_2_initialization(init_method, init_name):\n",
    "    num_methods = len(functions)\n",
    "    \n",
    "    for dimensions in dimensions_list:\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        all_dataset_ratios = np.zeros((num_datasets, num_methods, iterations))\n",
    "\n",
    "        for i in range(num_datasets):\n",
    "\n",
    "            data, _, true_centers = generate_pelleg_moore_data(dimensions, num_clusters, points_per_cluster, std_factor)\n",
    "            optimal_quality_values = experiment_2.run_kmeans(data, num_clusters, true_centers, optimal_kmeans_iterations, 1)\n",
    "\n",
    "            initial_centers = init_method(num_clusters, data)\n",
    "\n",
    "            ratios = experiment_2.run_experiment_dimensions_dataset(data, num_clusters, optimal_quality_values, initial_centers, functions, params)\n",
    "            all_dataset_ratios[i] = ratios\n",
    "        \n",
    "        avg_ratios = np.mean(all_dataset_ratios, axis=0)\n",
    "        plot_algorithms_ratio_quality_comparison(avg_ratios, names, PELLEG, init_name, dimensions, num_datasets, './')\n",
    "\n",
    "        print(f'Time to run {num_datasets} with {dimensions} dimensions: {time.time() - start_time:.2f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiment_2_initialization(initialize_centers_forgy, FORGY)\n",
    "run_experiment_2_initialization(initialzie_centers_random_partition, RANDPART)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 3: Semantic segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is one of the paper's experiment where the authors wanted to compare the performance of the K-Means and the K-Harmonic Means when performing \n",
    "# semantic segmentation of a particular image of a hand. They assesses the quality both visually and with the K-Means quality metric\n",
    "\n",
    "image_path = os.path.join(images_path, 'hand.png')\n",
    "image = load_image(image_path, (100, 100))\n",
    "scaler, image_data = generate_image_data(image)\n",
    "image_name = 'hand'\n",
    "\n",
    "# In the paper they say they used 5 clusters, but they did not include any of the other parameters. We are going to set them as follow:\n",
    "num_clusters = 5\n",
    "iterations = 500\n",
    "repetitions = 1\n",
    "\n",
    "# They also repeated the experiment with both Forgy and Random partition initialization of the clusters\n",
    "initial_centers_forgy = initialize_centers_forgy(num_clusters, image_data)\n",
    "initial_centers_rand_part = initialzie_centers_random_partition(num_clusters, image_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forgy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_means_function = experiment_3.run_kmeans\n",
    "kharmonic_function = experiment_3.run_kharmonic\n",
    "\n",
    "k_means_params = {\n",
    "        'iterations' : iterations,\n",
    "        'repetitions' : repetitions\n",
    "}\n",
    "\n",
    "kharmonic_params = {\n",
    "        'p' : 2,\n",
    "        'convergence_threshold' : 0.0001,\n",
    "        'iterations' : iterations,\n",
    "        'repetitions' : repetitions\n",
    "}\n",
    "\n",
    "experiment_3.run_semantic_segmentation(image, image_data, scaler, num_clusters, initial_centers_forgy, FORGY, KMEANS, \n",
    "        image_name, experiment_3_results_path, k_means_function, k_means_params)\n",
    "\n",
    "experiment_3.run_semantic_segmentation(image, image_data, scaler, num_clusters, initial_centers_forgy, FORGY, KHARMONIC, image_name,\n",
    "        experiment_3_results_path, kharmonic_function, kharmonic_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_3.run_semantic_segmentation(image, image_data, scaler, num_clusters, initial_centers_rand_part, RANDPART, KMEANS, image_name,\n",
    "        experiment_3_results_path, k_means_function, k_means_params)\n",
    "\n",
    "experiment_3.run_semantic_segmentation(image, image_data, scaler, num_clusters, initial_centers_rand_part, RANDPART, KHARMONIC, image_name,\n",
    "        experiment_3_results_path, kharmonic_function, kharmonic_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repeat the process increasing the number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusters = 10\n",
    "image_name = 'hand_10_clusters'\n",
    "\n",
    "initial_centers_forgy = initialize_centers_forgy(num_clusters, image_data)\n",
    "initial_centers_rand_part = initialzie_centers_random_partition(num_clusters, image_data)\n",
    "\n",
    "experiment_3.run_semantic_segmentation(image, image_data, scaler, num_clusters, initial_centers_forgy, FORGY, KMEANS, image_name,\n",
    "        experiment_3_results_path, k_means_function, k_means_params)\n",
    "\n",
    "experiment_3.run_semantic_segmentation(image, image_data, scaler, num_clusters, initial_centers_forgy, FORGY, KHARMONIC, image_name,\n",
    "        experiment_3_results_path, kharmonic_function, kharmonic_params)\n",
    "\n",
    "experiment_3.run_semantic_segmentation(image, image_data, scaler, num_clusters, initial_centers_rand_part, RANDPART, KMEANS, image_name,\n",
    "        experiment_3_results_path, k_means_function, k_means_params)\n",
    "\n",
    "experiment_3.run_semantic_segmentation(image, image_data, scaler, num_clusters, initial_centers_rand_part, RANDPART, KHARMONIC, image_name,\n",
    "        experiment_3_results_path, kharmonic_function, kharmonic_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 4: Compare K-Harmonic Means with some Sklearn algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adult dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and preprocess the data from the arff file, obtaining the true classification label (i.e. true cluster) and the feature names\n",
    "adult_arff_path = os.path.join(datasets_path, 'adult.arff')\n",
    "adult_object = AdultData(adult_arff_path, experiment_4_results_path)\n",
    "data, true_clustering, feature_names = adult_object.get_content()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA to determine the number of principal components that account for the 90% of the data variance\n",
    "pca_object = PCA()\n",
    "pca_object.fit(data)\n",
    "plot_pca_explained_variance(pca_object.explained_variance_ratio_, ADULT, experiment_4_results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at the generated plot, we see that we need the first 17 principal components\n",
    "number_of_pcs = 17\n",
    "pca_object = PCA(number_of_pcs)\n",
    "reduced_data = pca_object.fit_transform(data)\n",
    "\n",
    "# Let's plot the true clustering with the reduced data\n",
    "pca_feature_names = ['PC1', 'PC2', 'PC3']\n",
    "plot_clustering_3d(reduced_data, true_clustering, pca_feature_names, ADULT, 'Ground-truth', experiment_4_results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now run different algorithms, so we are going to define some common parameters to all the algorithms\n",
    "\n",
    "# List with the numbers of clusters to try\n",
    "k_values = range(2, 16)\n",
    "# Number of max iterations to run each algorithm\n",
    "iterations = 500\n",
    "# Number of repetitions with different initial centers\n",
    "repetitions = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sklearn K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first search for the optimal number of clusters using the elbow method\n",
    "# The true number of clusters is 2, so let's try a range between 2 and 15\n",
    "\n",
    "kmeans_function = experiment_4.run_sklearn_kmeans\n",
    "# We define some parameters as a dictionary as we have tried to create a unified framework to run the experiments\n",
    "kmeans_params = {\n",
    "    'iterations' : iterations,\n",
    "    'repetitions' : repetitions\n",
    "}\n",
    "\n",
    "experiment_4.search_optimal_number_of_clusters(reduced_data, k_values, SKLEARN_KMEANS, ADULT, experiment_4_results_path, kmeans_function, kmeans_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at the plot for the silhouette score to apply the elbow method (inverse in this case), we see that the optimal number of clusters is 4 (the point where is maximum)\n",
    "optimal_k_skmeans = 4\n",
    "\n",
    "# Let's now apply the algorithm again with this number of clusters\n",
    "skmeans_clustering, skmeans_centers = experiment_4.run_algorithm_with_optimal_k(reduced_data, optimal_k_skmeans, kmeans_function, kmeans_params)\n",
    "\n",
    "# Let's now compute some evaluation metrics, plot the resulting clustering, and save the predicted centers\n",
    "evaluate_resulting_clusters(reduced_data, true_clustering, skmeans_clustering, ADULT, SKLEARN_KMEANS, experiment_4_results_path)\n",
    "plot_clustering_3d(reduced_data, skmeans_clustering, pca_feature_names, ADULT, SKLEARN_KMEANS, experiment_4_results_path)\n",
    "\n",
    "skmeans_centers = pca_object.inverse_transform(skmeans_centers)\n",
    "skmeans_centers = adult_object.restore_center_features(skmeans_centers)\n",
    "write_cluster_centers_to_txt(skmeans_centers, feature_names, SKLEARN_KMEANS, ADULT, experiment_4_results_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### K-Harmonic Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's repeat all the process with the K-Harmonic Means algorithm (the one studied in the paper)\n",
    "kharmonic_function = experiment_4.run_kharmonic\n",
    "kharmonic_params = {\n",
    "    'p' : 2,\n",
    "    'convergence_threshold' : 0.001,\n",
    "    'iterations' : iterations,\n",
    "    'repetitions' : repetitions\n",
    "}\n",
    "\n",
    "#experiment_4.search_optimal_number_of_clusters(reduced_data, k_values, KHARMONIC, ADULT, experiment_4_results_path, kharmonic_function, kharmonic_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at the plot now we obtain 2 as the optimal number of clusters (the same as in the original data)\n",
    "optimal_k_kharmonic = 2\n",
    "\n",
    "kharmonic_clustering, kharmonic_centers = experiment_4.run_algorithm_with_optimal_k(reduced_data, optimal_k_kharmonic, kharmonic_function, kharmonic_params)\n",
    "\n",
    "evaluate_resulting_clusters(reduced_data, true_clustering, kharmonic_clustering, ADULT, KHARMONIC, experiment_4_results_path)\n",
    "plot_clustering_3d(reduced_data, kharmonic_clustering, pca_feature_names, ADULT, KHARMONIC, experiment_4_results_path)\n",
    "\n",
    "kharmonic_centers = pca_object.inverse_transform(kharmonic_centers)\n",
    "kharmonic_centers = adult_object.restore_center_features(kharmonic_centers)\n",
    "write_cluster_centers_to_txt(kharmonic_centers, feature_names, KHARMONIC, ADULT, experiment_4_results_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fuzzy C-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcmeans_function = experiment_4.run_fuzzy_c_means\n",
    "fcmeans_params = {\n",
    "    'fuzzy_degree' : 2,\n",
    "    'convergence_threshold' : 0.001,\n",
    "    'iterations' : iterations,\n",
    "    'repetitions' : repetitions\n",
    "}\n",
    "\n",
    "experiment_4.search_optimal_number_of_clusters(reduced_data, k_values, FCMEANS, ADULT, experiment_4_results_path, fcmeans_function, fcmeans_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_k_fuzzy = 2\n",
    "\n",
    "fcmeans_clustering, fcmeans_centers = experiment_4.run_algorithm_with_optimal_k(reduced_data, optimal_k_fuzzy, fcmeans_function, fcmeans_params)\n",
    "\n",
    "evaluate_resulting_clusters(reduced_data, true_clustering, fcmeans_clustering, ADULT, FCMEANS, experiment_4_results_path)\n",
    "plot_clustering_3d(reduced_data, fcmeans_clustering, pca_feature_names, ADULT, FCMEANS, experiment_4_results_path)\n",
    "\n",
    "fcmeans_centers = pca_object.inverse_transform(fcmeans_centers)\n",
    "fcmeans_centers = adult_object.restore_center_features(fcmeans_centers)\n",
    "write_cluster_centers_to_txt(fcmeans_centers, feature_names, FCMEANS, ADULT, experiment_4_results_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hybrid 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid1_function = experiment_4.run_hybrid_1\n",
    "\n",
    "experiment_4.search_optimal_number_of_clusters(reduced_data, k_values, HYBRID1, ADULT, experiment_4_results_path, hybrid1_function, kharmonic_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_k_h1 = 7\n",
    "\n",
    "h1_clustering, h1_centers = experiment_4.run_algorithm_with_optimal_k(reduced_data, optimal_k_h1, hybrid1_function, kharmonic_params)\n",
    "\n",
    "evaluate_resulting_clusters(reduced_data, true_clustering, h1_clustering, ADULT, HYBRID1, experiment_4_results_path)\n",
    "plot_clustering_3d(reduced_data, h1_clustering, pca_feature_names, ADULT, HYBRID1, experiment_4_results_path)\n",
    "\n",
    "h1_centers = pca_object.inverse_transform(h1_centers)\n",
    "h1_centers = adult_object.restore_center_features(h1_centers)\n",
    "write_cluster_centers_to_txt(h1_centers, feature_names, HYBRID1, ADULT, experiment_4_results_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hybrid 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid2_function = experiment_4.run_hybrid_2\n",
    "\n",
    "experiment_4.search_optimal_number_of_clusters(reduced_data, k_values, HYBRID2, ADULT, experiment_4_results_path, hybrid2_function, kharmonic_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_k_h2 = 2\n",
    "\n",
    "h2_clustering, h2_centers = experiment_4.run_algorithm_with_optimal_k(reduced_data, optimal_k_h2, hybrid2_function, kharmonic_params)\n",
    "\n",
    "evaluate_resulting_clusters(reduced_data, true_clustering, h2_clustering, ADULT, HYBRID2, experiment_4_results_path)\n",
    "plot_clustering_3d(reduced_data, h2_clustering, pca_feature_names, ADULT, HYBRID2, experiment_4_results_path)\n",
    "\n",
    "h2_centers = pca_object.inverse_transform(h2_centers)\n",
    "h2_centers = adult_object.restore_center_features(h2_centers)\n",
    "write_cluster_centers_to_txt(h2_centers, feature_names, HYBRID2, ADULT, experiment_4_results_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sklearn Gaussian EM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_EM_function = experiment_4.run_sklearn_gaussian_EM\n",
    "gaussian_EM_params = {\n",
    "    'convergence_threshold' : 0.001,\n",
    "    'iterations' : iterations,\n",
    "    'repetitions' : repetitions\n",
    "}\n",
    "\n",
    "#experiment_4.search_optimal_number_of_clusters(reduced_data, k_values, SKLEARN_GEM, ADULT, experiment_4_results_path, gaussian_EM_function, gaussian_EM_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_k_gaussian_EM = 2\n",
    "\n",
    "gaussian_EM_clustering, gaussian_EM_centers = experiment_4.run_algorithm_with_optimal_k(reduced_data, optimal_k_gaussian_EM, gaussian_EM_function, gaussian_EM_params)\n",
    "\n",
    "evaluate_resulting_clusters(reduced_data, true_clustering, gaussian_EM_clustering, ADULT, SKLEARN_GEM, experiment_4_results_path)\n",
    "plot_clustering_3d(reduced_data, gaussian_EM_clustering, pca_feature_names, ADULT, SKLEARN_GEM, experiment_4_results_path)\n",
    "\n",
    "gaussian_EM_centers = pca_object.inverse_transform(gaussian_EM_centers)\n",
    "gaussian_EM_centers = adult_object.restore_center_features(gaussian_EM_centers)\n",
    "write_cluster_centers_to_txt(gaussian_EM_centers, feature_names, SKLEARN_GEM, ADULT, experiment_4_results_path)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0700c7f74b45c332d3cae75f71229e241bbc846b934be310d892912689fa2754"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
